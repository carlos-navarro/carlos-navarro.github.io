---
title: "ðŸ‡ºðŸ‡¸ Rebooting AI (Gary Marcus, Ernest Davis)"
layout: post
date: 2023-02-21 12:00
tag:
- AI
- book
books: true
hidden: true # don't count this post in blog pagination
category: book
author: carlos-navarro
externalLink: false
---

<a 
    href="http://rebooting.ai">
    <img width="100"
        src="http://d2f0ora2gkri0g.cloudfront.net/65/88/6588cd87-6ad6-430a-ad38-d65df4876348.jpeg" 
        alt="Rebooting AI" />
</a>

<sub>Rebooting AI, New York, Pantheon Books, 2019</sub>

Marcus and Davis summarize in this book all the concerns that come to our minds with the success of AI tools such as ChatGPT or Stable Difussion. They claim they are optimistic but the mood of the book is quite pessimistic.

AI is a tool, an opportunity to create marvellous things. But AI, or better, Deep Learning is just a statistical tool. Hence, it fails. Always. Within a fixed percentage. Suddenly, like an idiot savant. 

AI needs supervision. It doesnâ€™t understand what it is doing. Its knowledge is brittle and can be fooled. It suffers from ethic/bias problems. **Itâ€™s only deep memorising not deep understanding**. It cannot take decisions. It deeply understands a single narrow domain (the one created by the big data that trained it) and under one single context. Must be retrained on slightly different contexts. **Hallucinates when you forces it to change to other contexts** (to other knowledge frameworks, to other micro theories). It relies on existing content. It steals. It's prone to IP problems. **Itâ€™s based in knowledge commonly held but itâ€™s neither common sense nor public domain content**.

[Is DL hitting a wall?](https://nautil.us/deep-learning-is-hitting-a-wall-238440/) (AI is not...)

On the other hand, the mood of Stephen Wolfram in his [long article about GPT](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/) is far more optimistic. 

I've found the relationship between AI and Thermodynamics very interesting: GPT doesnâ€™t choose always the highest-ranked word, or it will produce a very â€˜flatâ€™ essay, it picks, randomly, lower-ranked words, as often as a â€˜temperatureâ€™ parameter determines (0.8).

Thermodynamics again in [this article from O'Reilly's Make Magazine about Generative AI](https://makezine.com/article/craft/fine-art/generative-ai-for-makers-ai-has-truly-arrived-and-its-here-to-help-you-make-and-craft/):

> Many generative AI applications use diffusion model architecture under the hood. Diffusion models are a type of AI algorithm inspired by non-equilibrium thermodynamics. They add random noise to an input image and then learn to reconstruct a new, similar image from noise.

As John Grubber comments in [his post "Bing, the Most Exciting Product in Tech"](https://daringfireball.net/2023/02/bing_the_most_exciting_product_in_tech) referring to Wolfram's article:

> Any system complex enough to generate seemingly-original human language and thoughts is by definition too complex for us to truly understand. I find that thought both scary and beautiful.

Yes, AI is, today, scary and beautiful!
